{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "519355e6-4b74-4fdb-8421-29d1f59ae34a",
   "metadata": {},
   "source": [
    "# Module - 3 Web Scraping Essentials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd59d1d-be7d-45cf-a937-3feeb1570648",
   "metadata": {},
   "source": [
    "#### Learning Objective - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2583d937-ab0b-416f-8963-4cb244e7cc98",
   "metadata": {},
   "source": [
    "- What is an API?\n",
    "    - Client-server model\n",
    "    - REST vs SOAP (intro only)\n",
    "- HTTP methods: GET, POST, PUT, DELETE\n",
    "- Understanding endpoints, headers, status codes\n",
    "- Using the requests library to call APIs\n",
    "- Working with JSON data in Python\n",
    "    - Parsing JSON to Python dict\n",
    "    - Extracting nested values\n",
    "- Hands-on:\n",
    "    - Call a public API (e.g., OpenWeatherMap or JSONPlaceholder)\n",
    "    - Parse and print useful info from response\n",
    "\n",
    "\n",
    "- What is web scraping? When to use it?\n",
    "- Static vs dynamic websites\n",
    "- BeautifulSoup:\n",
    "    - Parsing HTML\n",
    "    - Finding tags, attributes, and text\n",
    "- Selenium (basic usage):\n",
    "    - Launching browser, finding elements\n",
    "    - Extracting values, clicking buttons\n",
    "- Playwright (intro only):\n",
    "    - Installing and setting up\n",
    "    - Simple headless scraping example\n",
    "- Ethical scraping: robots.txt, rate limits\n",
    "- Hands-on:\n",
    "    - Scrape titles/prices from a simple product listing page\n",
    "    - Compare results from BeautifulSoup and Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f63c3a6-ea6d-4683-b6c5-a3961056d999",
   "metadata": {},
   "source": [
    "## Introduction to API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa6ebe2-b074-4bc3-99b8-890c1c766521",
   "metadata": {},
   "source": [
    "- **API** stands for Application Programming Interface.\n",
    "- It is a set of protocols and tools that allow different software applications to communicate with each other.\n",
    "- **Key purposes:**\n",
    "   - Exposes data and functionality from one application to others.\n",
    "   - Acts as a contract between provider and consumer.\n",
    "- **APIs abstract implementation details**, letting consumers use functionalities without knowing internal workings.\n",
    "- Examples: Weather APIs, Payment gateway APIs, Mapping/Geolocation APIs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0397c54b",
   "metadata": {},
   "source": [
    "#### How APIs Work: The Client-Server Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dd29be",
   "metadata": {},
   "source": [
    "- **Client:** Application or system that sends requests for resources or actions (e.g., your Python script, web browser).\n",
    "- **Server:** Application or system that listens for requests and sends responses (e.g., a web server hosting the API).\n",
    "- **Interaction:**\n",
    "   - Client sends a request (usually over HTTP/S).\n",
    "   - Server processes the request and returns a response (data or status).\n",
    "- **Benefits of client-server model:**\n",
    "   - Separation of concerns.\n",
    "   - Easier scaling and maintenance.\n",
    "   - Enables distributed computing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6134ee",
   "metadata": {},
   "source": [
    "#### Making API Requests in Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d1eb8b",
   "metadata": {},
   "source": [
    "- Popular libraries for calling APIs in Python:\n",
    "   - `requests` (most common and beginner-friendly).\n",
    "   - `http.client` (standard library, lower level).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181b78a6",
   "metadata": {},
   "source": [
    "#### Introduction to REST and SOAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858af2dc-9fca-44b6-a34b-f1b093ef5082",
   "metadata": {},
   "source": [
    "- **REST (Representational State Transfer):**\n",
    "   - Lightweight architectural style for building APIs.\n",
    "   - Uses standard HTTP methods (GET, POST, PUT, DELETE).\n",
    "   - Data is often sent/received in JSON.\n",
    "   - Simple to use with Python's `requests` library.\n",
    "     \n",
    "- **SOAP (Simple Object Access Protocol):**\n",
    "   - Protocol for exchanging structured information.\n",
    "   - Uses XML for messages.\n",
    "   - More strict, with enveloping and schema requirements.\n",
    "   - Can be used in Python with libraries like `zeep` or `suds`.\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718bdb6b-11dd-4f5a-aa84-8f90d612f600",
   "metadata": {},
   "source": [
    "#### REST vs SOAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8635c49-0e04-403d-96da-c509ac305d07",
   "metadata": {},
   "source": [
    "<table style=\"width: 60%; border-collapse: collapse; border: 1px solid #ccc; margin-left: 0;\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: center; background-color: #050A30; color: white;\">\n",
    "      <th style=\"border: 1px solid #ccc; padding: 8px;\">Feature</th>\n",
    "      <th style=\"border: 1px solid #ccc; padding: 8px;\">REST</th>\n",
    "      <th style=\"border: 1px solid #ccc; padding: 8px;\">SOAP</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr style=\"text-align: center;\">\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px; text-align: left;\">Data Format</td>\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px;\">JSON (commonly), XML</td>\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px;\">XML only</td>\n",
    "    </tr>\n",
    "    <tr style=\"text-align: center;\">\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px; text-align: left;\">Python Library</td>\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px;\"><code>requests</code></td>\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px;\"><code>zeep</code>, <code>suds-py3</code></td>\n",
    "    </tr>\n",
    "    <tr style=\"text-align: center;\">\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px; text-align: left;\">Structure</td>\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px;\">Lightweight, less strict</td>\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px;\">Strict message structure</td>\n",
    "    </tr>\n",
    "    <tr style=\"text-align: center;\">\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px; text-align: left;\">Use Cases</td>\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px;\">Web apps, microservices</td>\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px;\">Enterprise apps, legacy</td>\n",
    "    </tr>\n",
    "    <tr style=\"text-align: center;\">\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px; text-align: left;\">Ease of Use</td>\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px;\">Very easy in Python</td>\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px;\">Moderate complexity</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "\n",
    "\n",
    "**Common Use Cases in Python Projects**\n",
    "- **REST APIs:**  \n",
    "   - Web scraping, automation, integrating third-party services (payment processing, social media, maps).\n",
    "- **SOAP APIs:**  \n",
    "   - Working with enterprise systems (banking, telecom), where SOAP remains prevalent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e64cca-9587-4e62-a546-d5e5689b6430",
   "metadata": {},
   "source": [
    "### Core HTTP Components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0342a4-6fc7-443e-96b8-9d863f03b776",
   "metadata": {},
   "source": [
    "#### 1. HTTP Methods\n",
    "\n",
    "HTTP methods define actions that can be performed on resources in web APIs. Python's `requests` library makes it easy to work with these methods when interacting with APIs.\n",
    "\n",
    "<table style=\"width: 80%; border-collapse: collapse; border: 1px solid #ccc; margin-left: 0;\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: center; background-color: #050A30; color: white;\">\n",
    "      <th style=\"border: 1px solid #ccc; padding: 8px;\">HTTP Method</th>\n",
    "      <th style=\"border: 1px solid #ccc; padding: 8px;\">Purpose</th>\n",
    "      <th style=\"border: 1px solid #ccc; padding: 8px;\">Idempotent?</th>\n",
    "      <th style=\"border: 1px solid #ccc; padding: 8px;\">Python <code>requests</code> Function</th>\n",
    "      <th style=\"border: 1px solid #ccc; padding: 8px;\">Typical Status Codes</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr style=\"text-align: center;\">\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px;\">GET</td>\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px; text-align: left;\">Retrieve data</td>\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px;\">Yes</td>\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px;\"><code>requests.get()</code></td>\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px;\">200 OK, 404 Not Found</td>\n",
    "    </tr>\n",
    "    <tr style=\"text-align: center;\">\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px;\">POST</td>\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px; text-align: left;\">Create new resource</td>\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px;\">No</td>\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px;\"><code>requests.post()</code></td>\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px;\">201 Created, 400 Bad Request</td>\n",
    "    </tr>\n",
    "    <tr style=\"text-align: center;\">\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px;\">PUT</td>\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px; text-align: left;\">Update/replace resource</td>\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px;\">Yes</td>\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px;\"><code>requests.put()</code></td>\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px;\">200 OK, 204 No Content</td>\n",
    "    </tr>\n",
    "    <tr style=\"text-align: center;\">\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px;\">DELETE</td>\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px; text-align: left;\">Delete resource</td>\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px;\">Yes</td>\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px;\"><code>requests.delete()</code></td>\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px;\">204 No Content, 404 Not Found</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "\n",
    "\n",
    "#### 2. Endpoints\n",
    "\n",
    "- **Definition:**  \n",
    "  An endpoint is a specific URL (Uniform Resource Locator) where an API can be accessed by a client to perform a particular function.\n",
    "- **Structure:**  \n",
    "  Typically follows the pattern:  \n",
    "  `https://api.example.com/resource`\n",
    "- **Examples:**  \n",
    "  - `https://api.example.com/users` – might return a list of users.\n",
    "  - `https://api.example.com/users/123` – fetches details of user with ID 123.\n",
    "  - Endpoints can change based on the resource or the method (GET/POST/PUT/DELETE).\n",
    "\n",
    "**In Python (using `requests`):**\n",
    "```python\n",
    "response = requests.get(\"https://api.example.com/items/5\")\n",
    "```\n",
    "\n",
    "#### 3. Headers\n",
    "\n",
    "- **Definition:**  \n",
    "  Headers are key-value pairs sent with the HTTP request or response to provide additional context, metadata, or instructions for client and server.\n",
    "- **Common Use Cases:**\n",
    "  - **Authentication:** e.g., `Authorization: Bearer `\n",
    "  - **Content-Type:** Specifies the format (e.g., `application/json`, `application/xml`) of the data.\n",
    "  - **Accept:** Informs the server what response format is expected.\n",
    "\n",
    "**In Python:**\n",
    "```python\n",
    "headers = {\n",
    "    \"Authorization\": \"Bearer \",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "response = requests.get(\"https://api.example.com/items\", headers=headers)\n",
    "```\n",
    "\n",
    "#### 4. Status Codes\n",
    "\n",
    "- **Definition:**  \n",
    "  Status codes are standardized 3-digit numbers returned with every HTTP response, providing information about the result of the request.\n",
    "- **Major Categories:**\n",
    "  - **200–299:** Success (e.g., 200 OK, 201 Created)\n",
    "  - **300–399:** Redirection (e.g., 301 Moved Permanently)\n",
    "  - **400–499:** Client Error (e.g., 400 Bad Request, 401 Unauthorized, 404 Not Found)\n",
    "  - **500–599:** Server Error (e.g., 500 Internal Server Error)\n",
    "- **How to use in Python:**\n",
    "  - Check `response.status_code` to determine how your code should react.\n",
    "\n",
    "```python\n",
    "response = requests.get(\"https://api.example.com/items\")\n",
    "if response.status_code == 200:\n",
    "    print(\"Success!\")\n",
    "elif response.status_code == 404:\n",
    "    print(\"Resource not found.\")\n",
    "else:\n",
    "    print(\"Error:\", response.status_code)\n",
    "```\n",
    "\n",
    "#### **Summary**\n",
    "\n",
    "<table style=\"width: 50%; border-collapse: collapse; border: 1px solid #ccc; margin-left: 0;\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: left; background-color: #050A30; color: white;\">\n",
    "      <th style=\"width: 20%;border: 1px solid #ccc; padding: 8px;\">Concept</th>\n",
    "      <th style=\"border: 1px solid #ccc; padding: 8px;\">Description</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px; font-weight: bold;\">Endpoints</td>\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px;\">\n",
    "        Are the addresses of specific API resources.\n",
    "      </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px; font-weight: bold;\">Headers</td>\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px;\">\n",
    "        Carry additional information, like authentication or content type.\n",
    "      </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px; font-weight: bold;\">Status codes</td>\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px;\">\n",
    "        Tell you if a request succeeded, redirected, failed, or broke due to a server error.\n",
    "      </td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fc7eaa-3e2c-47ee-9e64-fe45411a01d0",
   "metadata": {},
   "source": [
    "### Examples - Using the requests library to call APIs\n",
    "\n",
    "**Problem Statement:**\n",
    "Users need a simple way to programmatically interact with a shipment tracking system—retrieving shipment details and adding new consignments remotely via HTTP. Explore how to use Python's requests library to perform GET and POST requests to a real-world shipment REST API, enabling automation of these common tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f093aa-7181-4d26-81de-6f761a564087",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = r\"https://shipment-tracker-ehfh.onrender.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178f3018-da9e-444f-ae68-4ae8016ac05b",
   "metadata": {},
   "source": [
    "#### 1. GET (Retrieve Data)\n",
    "\n",
    "- Used to request data from a specified resource (API endpoint).\n",
    "- Does **not** modify data on the server.\n",
    "- Data is often passed via URL query parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183c0cb2",
   "metadata": {},
   "source": [
    "###### Ex. Get all the shipments and store them in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a97ff7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f102a1d5",
   "metadata": {},
   "source": [
    "###### Ex. Get shipment details by consignment ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1242859f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fe1b248",
   "metadata": {},
   "source": [
    "\n",
    "#### 2. POST (Create Data)\n",
    "\n",
    "- Used to send data to the server to create a new resource.\n",
    "- Data is included in the request body (usually JSON or form data).\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e4f513",
   "metadata": {},
   "source": [
    "###### Ex. Add a new shipment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c430379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4934bb35",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### 3. PUT (Update Data)\n",
    "\n",
    "- Used to update an existing resource fully or create if it doesn't exist.\n",
    "- Sends all fields of the resource; replaces the current representation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc1c949",
   "metadata": {},
   "source": [
    "###### Ex. Update status of consignment_id = DEL-00023 to Delivered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c89253",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87301fb6",
   "metadata": {},
   "source": [
    "\n",
    "#### 4. DELETE (Remove Data)\n",
    "\n",
    "- Used to delete a resource identified by a URI.\n",
    "- Typically returns status code 204 No Content on success.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a81aff1",
   "metadata": {},
   "source": [
    "###### Ex. Delete shipment by consignment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360eb421",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9031fe4-8230-4f0c-abcf-bd78b71d1ddb",
   "metadata": {},
   "source": [
    "## Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039cc20c-e3db-46be-aad1-a88654789fe6",
   "metadata": {},
   "source": [
    "Web scraping is the automated process of extracting data from websites. It involves using programs (called \"scrapers\" or \"bots\") to send requests to web pages, retrieve their contents (HTML, JSON, etc.), and parse out the desired information—such as tables, text, images, or links. Python libraries like BeautifulSoup, Scrapy, and Selenium are popular for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbad0030-5454-47a5-96d2-a9d829b34125",
   "metadata": {},
   "source": [
    "### Web Scraping usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb04b8ca-2b10-41d3-b698-d3579949cc9e",
   "metadata": {},
   "source": [
    "- Collecting large amounts of data from websites that do not provide a public API.\n",
    "- Aggregating product prices, reviews, or inventory from online stores.\n",
    "- Gathering news articles, research publications, or social media content for analysis.\n",
    "- Monitoring changes on websites (e.g., job postings or real estate listings).\n",
    "- Any situation where repeated, structured download of web-based public information is needed.\n",
    "\n",
    "**Important:**  \n",
    "Always respect website terms of use, robots.txt, and copyright laws. Prefer official APIs if available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05325dba-9c52-4ae3-be8e-7bea08013b10",
   "metadata": {},
   "source": [
    "### Static vs Dynamic Websites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2d8cc0-d801-43cc-8e71-4e14de28b946",
   "metadata": {},
   "source": [
    "<table style=\"width: 90%; border-collapse: collapse; border: 1px solid #ccc; margin-left: 0;\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: left; background-color: #050A30; color: white;\">\n",
    "      <th style=\"width: 15%;border: 1px solid #ccc; padding: 8px;\">Feature</th>\n",
    "      <th style=\"width: 35%;border: 1px solid #ccc; padding: 8px;\">Static Website</th>\n",
    "      <th style=\"width: 45%;border: 1px solid #ccc; padding: 8px;\">Dynamic Website</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px; text-align: left;\">Content Delivery</td>\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px;\">\n",
    "        Content is fixed in HTML, served as-is by server\n",
    "      </td>\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px;\">\n",
    "        Content is generated/manipulated on-the-fly via JavaScript, APIs, or server processes\n",
    "      </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px; text-align: left;\">Scraping Ease</td>\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px;\">\n",
    "        Easy to scrape—BeautifulSoup, Requests suffice\n",
    "      </td>\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px;\">\n",
    "        Harder to scrape—often need Selenium, Playwright, or to analyze API calls\n",
    "      </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px; text-align: left;\">Examples</td>\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px;\">\n",
    "        Blogs, documentation, company info pages\n",
    "      </td>\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px;\">\n",
    "        News feeds, social networks, dashboards, e-commerce product pages\n",
    "      </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px; text-align: left;\">Source Code</td>\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px;\">\n",
    "        Page source contains all visible data\n",
    "      </td>\n",
    "      <td style=\"border: 1px solid #ccc; padding: 8px;\">\n",
    "        Data may load asynchronously, not present in initial HTML\n",
    "      </td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "\n",
    "- **Static:** What you see in the page source is what appears in the browser.\n",
    "- **Dynamic:** Content may load after the page loads, requiring tools that mimic a browser or interact with backend APIs.\n",
    "\n",
    "**Summary:**  \n",
    "- Web scraping harvests website data automatically.\n",
    "- Static sites are easy to scrape; dynamic sites often require extra work.\n",
    "- Use web scraping when APIs aren’t available, but always act ethically and legally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f246185-e56c-46e6-9543-107d99382e17",
   "metadata": {},
   "source": [
    "### BeautifulSoup vs Selenium vs Playwright"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739a7a51-0d95-4cbd-b859-28a0e470e8c1",
   "metadata": {},
   "source": [
    "**A Comprehensive Comparison for Python Web Scraping and Automation**\n",
    "\n",
    "<table style=\"width: 90%; border-collapse: collapse; border: 1px solid #ccc; margin-left: 0;\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: left; background-color: #050A30; color: white;\">\n",
    "      <th>Feature / Tool</th>\n",
    "      <th>BeautifulSoup</th>\n",
    "      <th>Selenium</th>\n",
    "      <th>Playwright</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td><strong>Core Use</strong></td>\n",
    "      <td>Static HTML/XML parsing &amp; extraction</td>\n",
    "      <td>Browser automation, dynamic content, user interaction testing</td>\n",
    "      <td>Modern browser automation, dynamic JS content, testing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><strong>Best For</strong></td>\n",
    "      <td>Simple scraping, static pages</td>\n",
    "      <td>Dynamic sites, JS-heavy pages, UI testing, automation</td>\n",
    "      <td>Dynamic web pages, reliable scraping/testing, cross-browser</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><strong>How It Works</strong></td>\n",
    "      <td>Parses HTML/XML from text, doesn’t control browsers</td>\n",
    "      <td>Controls real browsers via WebDriver API</td>\n",
    "      <td>Controls browsers, high-level API, auto-waiting</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><strong>Python Implementation</strong></td>\n",
    "      <td><code>from bs4 import BeautifulSoup</code><br><code>soup = BeautifulSoup(html, 'parser')</code></td>\n",
    "      <td><code>from selenium import webdriver</code><br><code>driver = webdriver.Chrome()</code></td>\n",
    "      <td><code>from playwright.sync_api import sync_playwright</code><br>Use context/browser methods</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><strong>Handles JavaScript?</strong></td>\n",
    "      <td>❌ No (HTML must be fully loaded on fetch)</td>\n",
    "      <td>✅ Yes (executes JS in browser context)</td>\n",
    "      <td>✅ Yes (executes JS; modern async support)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><strong>User Interaction?</strong></td>\n",
    "      <td>❌ None</td>\n",
    "      <td>✅ Yes (click, type, scroll, etc.)</td>\n",
    "      <td>✅ Yes (click, type, fill, hover, etc.)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><strong>Speed/Performance</strong></td>\n",
    "      <td>Very fast (text parsing only)</td>\n",
    "      <td>Slow (full browser launch for each session)</td>\n",
    "      <td>Faster than Selenium (uses WebSockets, modern engines)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><strong>Setup Complexity</strong></td>\n",
    "      <td>Simple: <code>pip install beautifulsoup4</code><br>Needs <code>requests</code></td>\n",
    "      <td>Medium: <code>pip install selenium</code>, install browser driver</td>\n",
    "      <td>Simple: <code>pip install playwright</code>, then <code>playwright install</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><strong>Resource Usage</strong></td>\n",
    "      <td>Minimal CPU/RAM</td>\n",
    "      <td>High (opens browsers)</td>\n",
    "      <td>High (browsers bundled; efficient parallel runs)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><strong>Supports Screenshots?</strong></td>\n",
    "      <td>❌ No</td>\n",
    "      <td>✅ Yes</td>\n",
    "      <td>✅ Yes</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><strong>Headless Mode?</strong></td>\n",
    "      <td>Not applicable</td>\n",
    "      <td>✅ Yes</td>\n",
    "      <td>✅ Yes (default)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><strong>Waits for Content</strong></td>\n",
    "      <td>❌ No (parses only supplied HTML)</td>\n",
    "      <td>Needs manual waits or explicit waits</td>\n",
    "      <td>✅ Built-in auto-waiting for elements/actions</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><strong>Browser Automation</strong></td>\n",
    "      <td>❌ No</td>\n",
    "      <td>✅ Yes</td>\n",
    "      <td>✅ Yes</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><strong>Community/Ecosystem</strong></td>\n",
    "      <td>Large, mature</td>\n",
    "      <td>Very large, mature</td>\n",
    "      <td>Growing, newer but developer-friendly</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><strong>Learning Curve</strong></td>\n",
    "      <td>Low</td>\n",
    "      <td>Moderate (web concepts, dealing with WebDriver)</td>\n",
    "      <td>Moderate (modern async, rich API)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><strong>Licensing</strong></td>\n",
    "      <td>Open source (BSD 3-Clause, permissive for commercial/proprietary use)</td>\n",
    "      <td>Open source (Apache 2.0, commercial/proprietary allowed)</td>\n",
    "      <td>Open source (Apache 2.0, permissive for commercial use)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><strong>Typical Use Cases</strong></td>\n",
    "      <td>Static sites, quick prototyping, parsing HTML files</td>\n",
    "      <td>Web app testing, scraping dynamic/interactive sites</td>\n",
    "      <td>Modern apps, cross-browser testing, reliable scraping</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><strong>Limitations</strong></td>\n",
    "      <td>Can’t handle JS content or user input</td>\n",
    "      <td>Slow; complex setup for large suites; struggles with some dynamic elements</td>\n",
    "      <td>Larger install, new community, some browser quirks</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "**Strengths & Weaknesses at a Glance**\n",
    "\n",
    "**BeautifulSoup**\n",
    "- **Pros:** Fast, easy, minimal setup, lightweight, ideal for static content.\n",
    "- **Cons:** Can’t execute JavaScript, no automation, can’t interact with UI, unsuitable for dynamic pages.\n",
    "- **Licensing:** BSD 3-Clause; fully open for commercial and proprietary use\n",
    "\n",
    "**Selenium**\n",
    "- **Pros:** Supports dynamic JS sites, full browser automation, broad language/browser support, huge ecosystem and integrations.\n",
    "- **Cons:** Slower (full browsers), higher resource use, complex setup with drivers, more fragile to website changes, handling dynamic elements can be tricky, steeper learning curve.\n",
    "- **Licensing:** Apache 2.0; open for commercial use.\n",
    "\n",
    "**Playwright**\n",
    "- **Pros:** Fast (uses WebSockets, parallel runs), supports rich modern web features, auto-waiting, reliable cross-browser automation, easy element handling, strong support for headless operation; modern API.\n",
    "- **Cons:** Newer, smaller community, larger install size, more complex with many features, some advanced browser quirks, requires managing versions.\n",
    "- **Licensing:** Apache 2.0; open for commercial/proprietary use.\n",
    "\n",
    "Why This Matters for Choosing Libraries:\n",
    "If it's SSR, you can use Beautiful Soup or similar parsers directly on the fully rendered HTML.\n",
    "\n",
    "If it’s CSR (dynamic content via JavaScript fetch), Beautiful Soup alone won’t see the final data — you’ll need tools like Selenium to render the JavaScript or parse the JSON API responses directly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cc919d-7372-427d-ae3c-a6192b5c3eca",
   "metadata": {},
   "source": [
    "### Python Example: Minimal Implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b4c31d-9e6d-46dd-bc4c-e91dab3283d8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "**BeautifulSoup:**\n",
    "```python\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "html = requests.get('https://example.com').text\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "print(soup.title.text)\n",
    "```\n",
    "**Selenium:**\n",
    "```python\n",
    "from selenium import webdriver\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://example.com')\n",
    "print(driver.title)\n",
    "driver.quit()\n",
    "```\n",
    "**Playwright:**\n",
    "```python\n",
    "from playwright.sync_api import sync_playwright\n",
    "with sync_playwright() as p:\n",
    "    browser = p.chromium.launch()\n",
    "    page = browser.new_page()\n",
    "    page.goto('https://example.com')\n",
    "    print(page.title())\n",
    "    browser.close()\n",
    "```\n",
    "\n",
    "**Licensing/Usage**\n",
    "\n",
    "- **No license fees required** for any of these tools; all are open source. Permissive licenses mean you can use them in commercial and closed-source projects, distribute, and modify them freely[7][8].\n",
    "\n",
    "**Bottom Line:**  \n",
    "- Use **BeautifulSoup** for simple, static sites: fastest and lightest.\n",
    "- Use **Selenium** or **Playwright** for JS-heavy, interactive, or test automation: Playwright is typically more modern and faster, Selenium has broader support and a larger legacy ecosystem.\n",
    "- All can be used freely in both personal and commercial projects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f150f5-242e-4337-ad34-238907b6d1bf",
   "metadata": {},
   "source": [
    "### Ethical Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09211d36-f727-4bf3-8f58-4a2003f9121a",
   "metadata": {},
   "source": [
    "**Ethical scraping** means collecting web data responsibly, respecting both the technical boundaries set by website owners and broader legal/ethical considerations. Two fundamental pillars of ethical scraping are: (1) obeying a site’s `robots.txt`, and (2) adhering to reasonable rate limits.\n",
    "\n",
    "**1. What is `robots.txt`?**\n",
    "\n",
    "- `robots.txt` is a simple text file placed in the root directory of a website (e.g., `https://example.com/robots.txt`) as part of the Robots Exclusion Protocol.\n",
    "- This file communicates *which parts* of a website *can* and *cannot* be accessed by automated bots, including web scrapers and search engine crawlers.\n",
    "- Main directives in `robots.txt`:\n",
    "  - `User-agent`: specifies which bot(s) the rule applies to (e.g., Googlebot, or all: `*`).\n",
    "  - `Disallow`: URLs/folders that should not be crawled.\n",
    "  - `Allow`: exceptions to Disallow rules (used more in Google’s implementation).\n",
    "  - `Crawl-delay`: specifies how many seconds a bot should wait between requests. Not all bots observe this.\n",
    "- Example:\n",
    "  ```\n",
    "  User-agent: *\n",
    "  Disallow: /private/\n",
    "  Allow: /public/\n",
    "  Crawl-delay: 10\n",
    "  ```\n",
    "- While not legally binding everywhere, *respecting robots.txt is considered foundational to ethical web scraping*. Websites may set honeypot traps or block noncompliant bots that ignore it.\n",
    "\n",
    "**2. Why Respect `robots.txt`?**\n",
    "\n",
    "- It’s a way for website owners to protect private, sensitive, or resource-intensive areas from automated scraping.\n",
    "- Sites may restrict bots from crawling admin panels, search result pages, or massive archives to avoid excessive server load and protect privacy.\n",
    "- Disregarding robots.txt:\n",
    "  - Is considered *unethical* by the data community.\n",
    "  - Risks you being blocked, blacklisted, or even facing legal action.\n",
    "  - May harm a website by overloading it, especially if you hit disallowed sections.\n",
    "- Respecting it keeps you within the “good bot” norms and reduces your risk profile.\n",
    "\n",
    "**3. What Are Rate Limits? Why Are They Important?**\n",
    "\n",
    "- **Rate limiting** is how websites restrict the number of requests you (or your bot) can make over a period (e.g., 10 requests per minute) to prevent server overload and abuse.\n",
    "- Web servers monitor request rates per IP, User-Agent, or session. Exceeding their threshold triggers blocking, CAPTCHAs, or rate-limiting HTTP errors (429 “Too Many Requests”).\n",
    "- Even if a site’s robots.txt doesn’t mention crawl delays, ethical scraping means avoiding “hammering” the site with rapid-fire requests.\n",
    "\n",
    "**Best Practices:**\n",
    "- Begin with conservative request rates: often 1 request every 10–30 seconds. Some recommend never exceeding 1,000 requests per IP per day for major sites; even less for smaller sites.\n",
    "- Look for `Crawl-delay` in robots.txt, and always obey it if present (e.g., `Crawl-delay: 5` means at least 5 seconds between requests).\n",
    "- Randomize your delays and monitor for HTTP 429 errors or CAPTCHAs.\n",
    "- Respect business hours and slow down during peak times.\n",
    "- Rotate IPs/users if necessary, but never to circumvent clear restrictions.\n",
    "\n",
    "**4. Additional Ethical Practices**\n",
    "\n",
    "- Always check and abide by the website’s Terms of Service or usage policies.\n",
    "- Prefer official APIs when available instead of scraping HTML.\n",
    "- Avoid collecting sensitive or personal data unless explicitly permitted.\n",
    "- Identify your scraper with a meaningful User-Agent string; do not misrepresent your bot as a browser if you are scraping.\n",
    "- Consider reaching out for permission before scraping large volumes of data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195a5dca-f8da-4c47-9c7e-f27b1f301c4c",
   "metadata": {},
   "source": [
    "### Examples - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c962c7c2-fb8e-4c6f-be3b-d45236257c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = r\"https://shipment-tracker-ehfh.onrender.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a46b55c-67ab-419f-b69f-962233cbd91f",
   "metadata": {},
   "source": [
    "###### Ex. Extract list of container shipping companies from wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e74bfe-0eda-4150-914e-1f52385ed3cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d54d8a26-5afe-4030-8324-eeb4df73aae4",
   "metadata": {},
   "source": [
    "###### Ex. Extract all the shipment details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c37f899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46360bbf-c209-453a-a405-c3d62983e861",
   "metadata": {},
   "source": [
    "##### Note - \n",
    "\n",
    "- BeautifulSoup is an HTML parsing library designed to work with static websites.  \n",
    "- Static websites deliver full page content directly in the initial HTML response from the server.  \n",
    "- BeautifulSoup parses this static HTML effectively to extract required data.  \n",
    "- Many modern websites use JavaScript to dynamically generate or update content after the initial page load.  \n",
    "- Such dynamic content is commonly rendered via client-side rendering or AJAX calls.  \n",
    "- BeautifulSoup **cannot execute JavaScript**, so it cannot see or parse dynamically generated content.  \n",
    "- For websites with JavaScript-driven dynamic content, you need a tool that can render the page as a real browser would.  \n",
    "- Selenium automates a web browser and fully renders pages including executing JavaScript.  \n",
    "- Using Selenium allows you to access the complete, up-to-date DOM after JavaScript has run.  \n",
    "- Therefore, for dynamic JavaScript-based websites, **Selenium (or similar tools) must be used instead of BeautifulSoup** alone. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2f9f07-42da-402f-b1f3-0ed8766b8113",
   "metadata": {},
   "source": [
    "**Selenium + BeautifulSoup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7639bfe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c17b9fd-04ab-4f9c-b57f-80bcda4ba817",
   "metadata": {},
   "source": [
    "**Only Selenium**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f35bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3625aef-140e-412b-98fd-6f3a9f58de7c",
   "metadata": {},
   "source": [
    "###### Ex. Extract all the delivered shipment details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8f6f29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a30e69ac-39d0-4065-96f1-04813350b89e",
   "metadata": {},
   "source": [
    "###### Ex. Get Consigment details by consignment ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac88fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83277a89-9099-4bb6-b5e5-dde016b81d22",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Cheat Sheets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ad47fb-37c7-43cd-8948-33b92a709499",
   "metadata": {},
   "source": [
    "#### Beautiful Soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb57c6e-3c7a-4ee0-8ec6-7e85c3cd12aa",
   "metadata": {},
   "source": [
    "**Install & Import**\n",
    "\n",
    "```bash\n",
    "pip install beautifulsoup4 requests\n",
    "```\n",
    "\n",
    "```python\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Fetch & Parse HTML**\n",
    "\n",
    "```python\n",
    "url = \"https://example.com\"\n",
    "html = requests.get(url).text\n",
    "soup = BeautifulSoup(html, \"html.parser\")  # or \"lxml\" if installed\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Finding Elements**\n",
    "\n",
    "**- Find first matching element**\n",
    "\n",
    "```python\n",
    "soup.find('h1')  \n",
    "soup.find('div', {'class': 'product'})\n",
    "```\n",
    "\n",
    "**- Find all matching elements**\n",
    "\n",
    "```python\n",
    "soup.find_all('a')  \n",
    "soup.find_all('div', {'class': 'item'})\n",
    "```\n",
    "\n",
    "**- Find by ID**\n",
    "\n",
    "```python\n",
    "soup.find(id='main-content')\n",
    "```\n",
    "\n",
    "**- CSS Selectors**\n",
    "\n",
    "```python\n",
    "soup.select('.classname')      # class\n",
    "soup.select('#idname')         # id\n",
    "soup.select('div > p')         # child\n",
    "soup.select('table.wikitable') # tag + class\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Get Text & Attributes**\n",
    "\n",
    "```python\n",
    "tag = soup.find('a')\n",
    "\n",
    "tag.get_text()      # text inside tag\n",
    "tag.text            # same as above\n",
    "tag['href']         # value of href attribute\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Looping Over Multiple Elements**\n",
    "\n",
    "```python\n",
    "for link in soup.find_all('a'):\n",
    "    print(link.get_text(), link['href'])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Navigating**\n",
    "\n",
    "```python\n",
    "element.parent            # go up one level\n",
    "element.children          # iterate child elements\n",
    "element.next_sibling      # next element at same level\n",
    "element.previous_sibling  # previous element\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Tables → DataFrame (Pandas)**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "table = soup.find('table', {'class': 'wikitable'})\n",
    "df = pd.read_html(str(table))[0]\n",
    "print(df.head())\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Cleaning Text**\n",
    "\n",
    "```python\n",
    "text = tag.get_text(strip=True)  # remove extra spaces & newlines\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Common Patterns**\n",
    "\n",
    "| Goal                | Code                                                     |\n",
    "| ------------------- | -------------------------------------------------------- |\n",
    "| All links on page   | `[a['href'] for a in soup.find_all('a', href=True)]`     |\n",
    "| All images          | `[img['src'] for img in soup.find_all('img', src=True)]` |\n",
    "| First heading       | `soup.find('h1').text`                                   |\n",
    "| All rows of a table | `soup.find_all('tr')`                                    |\n",
    "\n",
    "---\n",
    "\n",
    "**Tips**\n",
    "\n",
    "* Use **`soup.prettify()`** to format HTML for inspection.\n",
    "* Use browser **Inspect** tool to find tags/classes/IDs.\n",
    "* Respect **robots.txt** and terms of service."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
